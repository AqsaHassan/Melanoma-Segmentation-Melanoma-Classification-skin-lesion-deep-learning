# -*- coding: utf-8 -*-
"""HAM1000(ISIIC2018).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13hYcRjwEOcSNujL9_XpTN2Ev-1fPL-BH
"""

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import os
from glob import glob
import seaborn as sns
from PIL import Image
from skimage.io import imread
from PIL import Image


from sklearn.model_selection import train_test_split
from keras.utils.np_utils import to_categorical # convert to one-hot-encoding

from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import layers
from tensorflow.keras import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ReduceLROnPlateau
# %matplotlib inline

import matplotlib.pyplot as plt
from matplotlib import pyplot as plt

#from google.colab import drive
#drive.mount('/content/drive')

# Set the ROOT_DIR variable to the root directory of the HAMdataset
#ROOT_DIR = '/content/drive/MyDrive/HAMdataset'
#assert os.path.exists(ROOT_DIR), 'ROOT_DIR does not exist. Did you forget to read the instructions above? ;)'

#base_skin_dir = "/Users/Hoang/Machine_Learning/skin_cancer/skin-cancer-mnist-ham10000"

base_skin_dir='/home/aqsah/projects/isic2018/isic2018/segment'

skin_df = pd.read_csv(os.path.join(base_skin_dir, 'HAM10000_metadata')) # load in the data
print('check')
print(skin_df)
skin_df.head()

#DICTIONARY CREATION

imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x
                     for x in glob(os.path.join(base_skin_dir, 'SegmentedImage', '*.jpg'))}


lesion_type_dict = {
    'nv': 'Melanocytic_nevi',
    'mel': 'melanoma',
    'bkl': 'Benign_keratosis-like_lesions',
    'bcc': 'Basal_cell_carcinoma',
    'akiec': 'Actinic_keratoses',
    'vasc': 'Vascular_lesions',
    'df': 'Dermatofibroma'
}

lesion_danger = {
    'nv': 0, # 0 for benign
    'mel': 1, # 1 for malignant
    'bkl': 0, # 0 for benign
    'bcc': 1, # 1 for malignant
    'akiec': 1, # 1 for malignant
    'vasc': 0,
    'df': 0
}
print(lesion_danger)

skin_df["path"] = skin_df["image_id"].map(imageid_path_dict.get) # map image_id to the path of that image

skin_df["path"] = skin_df["image_id"].map(imageid_path_dict.get) # map image_id to the path of that image

skin_df["cell_type"] = skin_df["dx"].map(lesion_type_dict.get) # map dx to type of lesion

skin_df["Malignant"] = skin_df["dx"].map(lesion_danger.get)

skin_df.head()

skin_df["cell_type_idx"] = pd.Categorical(skin_df["cell_type"]).codes # give each cell type a category id

skin_df["image"] = skin_df["path"].map(imread)

#Reshape image and get data for classification
reshaped_image = skin_df["path"].map(lambda x: np.asarray(Image.open(x).resize((64,64), resample=Image.LANCZOS).\
                                                          convert("RGB")).ravel())

out_vec = np.stack(reshaped_image, 0)

out_df = pd.DataFrame(out_vec)

out_df["label"] = skin_df["cell_type_idx"]
out_df.head()
out_path = "/home/aqsah/projects/isic2018/isic2018/HAM10000/hmnist_64_64_RGB.csv"
out_df.to_csv(out_path, index=False)

"""Resize Image for Retraining Model"""

img = Image.open(skin_df["path"][0])
img.size

skin_df["cell_type"].unique()

skin_df["path"][0]

for index in skin_df.index.values.tolist():
    path = skin_df.iloc[index]["path"]
    cell_type_idx = skin_df.iloc[index]["cell_type"]
    img_id = skin_df.iloc[index]["image_id"]
    newpath = f"/home/aqsah/projects/isic2018/isic2018/HAM10000/{cell_type_idx}/{img_id}.jpg"
    img = Image.open(path)
    img = img.resize((299, 299), resample=Image.LANCZOS)
    img.save(newpath)

"""**Resize Image for Keras Fine-Tuning Model**"""

reshaped_image = skin_df["path"].map(lambda x: np.asarray(Image.open(x).resize((256,192), resample=Image.LANCZOS).\
                                                          convert("RGB")))

out_vec = np.stack(reshaped_image, 0)
out_vec.shape
out_vec = out_vec.astype("float32")
out_vec /= 255

labels = skin_df["cell_type_idx"].values
from sklearn.model_selection import train_test_split
X_train_orig, X_test, y_train_orig, y_test = train_test_split(out_vec, labels, test_size=0.1,random_state=0)
np.save("256_192_test.npy", X_test)
np.save("test_labels.npy", y_test)
X_train, X_val, y_train, y_val = train_test_split(X_train_orig, y_train_orig, test_size=0.1, random_state=1)
np.save("256_192_val.npy", X_val)
np.save("val_labels.npy", y_val)
np.save("256_192_train.npy", X_train)
np.save("train_labels.npy", y_train)

"""**Load In the Data**"""
print(skin_df)
#base_skin_dir2='/home/aqsah/projects/isic2018/isic2018/HAM10000/hmnist_64_64_RGB.csv'
#skin_df = pd.read_csv(glob(os.path.join(base_skin_dir, 'HAM10000', 'hmnist_64_64_RGB.csv'))
skin_df = pd.read_csv('/home/aqsah/projects/isic2018/isic2018/HAM10000/hmnist_64_64_RGB.csv')
skin_df.head()

#X = skin_df.drop("label", axis=1).as_matrix()
X= skin_df.drop("label", axis=1).values
label = skin_df["label"].values

X.shape, label.shape

"""**Scaling and Split Data into Train, Validation and Test set**"""
X_mean = np.mean(X)
X_std = np.std(X)

X = (X - X_mean)/X_std
X_train_orig, X_test, y_train_orig, y_test = train_test_split(X, label, test_size=0.1,random_state=0)
X_train_orig.shape, X_test.shape, y_train_orig.shape, y_test.shape

X_train, X_val, y_train, y_val = train_test_split(X_train_orig, y_train_orig, test_size=0.2, random_state=1)
X_train.shape, X_val.shape, y_train.shape, y_val.shape

#Reshape the Data to Input in CNN
X_train = X_train.reshape(X_train.shape[0], *(64, 64, 3))
X_val = X_val.reshape(X_val.shape[0], *(64, 64, 3))
X_test = X_test.reshape(X_test.shape[0], *(64, 64, 3))
X_train.shape, X_val.shape, X_test.shape

y_train.shape
y_train = to_categorical(y_train)
y_val = to_categorical(y_val)
y_test = to_categorical(y_test)
y_train.shape, y_val.shape, y_test.shape

# Our input feature map is 64x64x3: 64x64 for the image pixels, and 3 for
# the three color channels: R, G, and B
img_input = layers.Input(shape=(64, 64, 3))

# First convolution extracts 16 filters that are 3x3
# Convolution is followed by max-pooling layer with a 2x2 window
x = layers.Conv2D(16, 3, activation='relu', padding='same')(img_input)
x = layers.MaxPooling2D(2)(x)

# Second convolution extracts 32 filters that are 3x3
# Convolution is followed by max-pooling layer with a 2x2 window
x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)
x = layers.MaxPooling2D(2)(x)

# Third convolution extracts 64 filters that are 3x3
# Convolution is followed by max-pooling layer with a 2x2 window
x = layers.Convolution2D(64, 3, activation='relu', padding='same')(x)
x = layers.MaxPooling2D(2)(x)

# Flatten feature map to a 1-dim tensor
x = layers.Flatten()(x)

# Create a fully connected layer with ReLU activation and 512 hidden units
x = layers.Dense(512, activation='relu')(x)

# Add a dropout rate of 0.5
x = layers.Dropout(0.5)(x)

# Create output layer with a single node and sigmoid activation
output = layers.Dense(7, activation='softmax')(x)

# Configure and compile the model
model = Model(img_input, output)

optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)

model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])

model.summary()

"""Define Data Generator for Data Augmentation and Learning Rate Adaptive Reduction to Prevent Overfitting"""

train_datagen = ImageDataGenerator(rotation_range=40, width_shift_range=0.2, height_shift_range=0.2,
                             shear_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode='nearest')

train_datagen.fit(X_train)

val_datagen = ImageDataGenerator()
val_datagen.fit(X_val)

learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=1, factor=0.5, min_lr=0.00001)
batch_size = 64
epochs = 50
#epochs= 2

history = model.fit_generator(train_datagen.flow(X_train,y_train, batch_size=batch_size),
                              epochs = epochs, validation_data = val_datagen.flow(X_val, y_val),
                              verbose = 1, steps_per_epoch=(X_train.shape[0] // batch_size),
                              callbacks=[learning_rate_reduction])


loss_test, acc_test = model.evaluate(X_test, y_test, verbose=1)
loss_val, acc_val = model.evaluate(X_val, y_val, verbose=1)
print("Validation: accuracy = %f  ;  loss_v = %f" % (acc_val, loss_val))
print("Test: accuracy = %f  ;  loss = %f" % (acc_test, loss_test))
model.save("modelsegmented.h5")

# Retrieve a list of accuracy results on training and test data
# sets for each training epoch
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

# Retrieve a list of list results on training and test data
# sets for each training epoch
loss = history.history['loss']
val_loss = history.history['val_loss']

# Get number of epochs
epochs = range(len(acc))

# Plot training and validation accuracy per epoch
plt.plot(epochs, acc)
plt.plot(epochs, val_acc)
plt.title('Training and validation accuracy')
plt.savefig('SegmentedBASELINEaccuracy.png')

# Plot training and validation loss per epoch
plt.figure()
plt.plot(epochs, loss)
plt.plot(epochs, val_loss)
plt.title('Training and validation loss')
plt.savefig('SegmentedBASELINEloss.png')

